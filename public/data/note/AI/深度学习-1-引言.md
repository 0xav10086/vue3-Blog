# 引言
AI 系统需要具备自己获取知识的能力，即从原始数据中提取模式的能力,这种能力称为机器学习(machine learning)。

使用机器学习来发掘表示本身，而不仅仅把表示映射到输出,这种方法我们称之为表示学习(representation learning)

表示学习算法的典型例子是自编码器(autoencoder)。<br>自编码器由一个编码器(encoder)函数和一个解码器(decoder)函数组合而成。<br>码器函数将输入数据转换为一种不同的表示，而解码器函数则将这个新的表示转换回原来的形式。

当设计特征或设计用于学习特征的算法时，我们的目标通常是分离出能解释观察数据的变差因素(factors of variation)

深度学习(deep learning)通过其他较简单的表示来表达复杂表示，解决了表示学习中的**核心问题**(从原始数据中提取高层次、抽象的特征是非常困难的)。

深度学习模型的典型例子是前馈深度网络或多层感知机(multilayer perceptron,MLP)

![img.png]((../../images/EnglishImages/img.png)<br>
深度学习模型的示意图。<br>计算机难以理解原始感观输入数据的含义，如表示为像素值集合的图像。<br>将一组像素映射到对象标识的函数非常复杂。如果直接处理，学习或评估此映射似乎是不可能的。<br>深度学习将所需的复杂映射分解为一系列嵌套的简单映射(每个由模型的不同层描述)来解决这一难题。<br>输入展示在可见层(visible layer)，这样命名的原因是因为它包含我们能观察到的变量。<br>然后是一系列从图像中提取越来越多抽象特征的隐藏层(hidden layer)。因为它们的值不在数据中给出，所以将这些层称为“隐藏层”;<br>模型必须确定哪些概念有利于解释观察数据中的关系。<br>这里的图像是每个隐藏单元表示的特征的可视化。<br>给定像素，第1层可以轻易地通过比较相邻像素的亮度来识别边缘。<br>有了第1隐藏层描述的边缘，第2隐藏层可以容易地搜索可识别为角和扩展轮廓的边集合。<br>给定第2隐藏层中关于角和轮廓的图像描述，第3隐藏层可以找到轮廓和角的特定集合来检测特定对象的整个部分。<br>最后，根据图像描述中包含的对象部分，可以识别图像中存在的对象

目前主要有两种度量模型深度的方式:
- 基于评估架构所需执行的顺序指令的数目
    - 将模型表示为给定输入后，计算对应输出的流程图，则可以将这张流程图中的最长路径视为模型的深度
    - ![img.png]((../../images/EnglishImages/img1.png)
    - 将输入映射到输出的计算图表的示意图，其中每个节点执行一个操作。深度是从输入到输出的最长路径的长度，但这取决于可能的计算步骤的定义。这些图中所示的计算是逻辑回归模型的输出，σ(wTx)，其中σ是logistic sigmoid函数。如果使用加法、乘法和logistic sigmoid作为计算机语言的元素，那么这个模型深度为3；如果将逻辑回归视为元素本身，那么这个模型深度为1
- 描述概念彼此如何关联的图的深度
  - 计算每个概念表示的计算流程图的深度可能比概念本身的图更深。这是因为系统对较简单概念的理解在给出更复杂概念的信息后可以进一步精细化
  - 细化每个概念的估计将需要额外的n次计算，那么计算的图将包含2n层

![img.png]((../../images/EnglishImages/img3.png)<br>
流程图展示了AI系统的不同部分如何在不同的AI学科中彼此相关。阴影框表示能从数据中学习的组件